{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "U7tBExIyrXJB"
      },
      "outputs": [],
      "source": [
        "import numpy as np # import numpy for matrix operations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "j6ANmhJbrXJD"
      },
      "outputs": [],
      "source": [
        "### this function load data from .dat file\n",
        "def load_dat(filename):\n",
        "    with open(filename, 'r') as fin:\n",
        "        lines = fin.readlines()\n",
        "        dim = len(lines[0].strip().split())\n",
        "        num_samples = len(lines)\n",
        "        data = np.zeros((num_samples, dim))\n",
        "        for i in range(num_samples):\n",
        "            data[i, :] = np.array([float(x) for x in lines[i].strip().split()])\n",
        "        return data "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "NIQt8ZC1rXJG"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "X (47 x 2)\n",
            "Y (47)\n"
          ]
        }
      ],
      "source": [
        "### load data\n",
        "# call the load_dat function to load X and Y from the corresponding input files\n",
        "X = load_dat(\"ex2x.dat\") # in this case, dim 2 so we have 2 variables\n",
        "Y =  load_dat(\"ex2y.dat\") # output is dim 1\n",
        "# get some statistics of the data\n",
        "num_samples = X.shape[0] # get the first dimension of X (i.e. number of rows), so number of samples\n",
        "dim = X.shape[1] # get the second dimension of X (i.e. number of columns), so number of variables\n",
        "print('X (%d x %d)' %(num_samples, dim))\n",
        "print('Y (%d)' %(num_samples))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J9eH3V0drXJH"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "X (47 x 3)\n",
            "Y (47 x 1)\n"
          ]
        }
      ],
      "source": [
        "### add intercept term to all samples in X\n",
        "# practical to use np.ones, the learned beta_0 will then give the intercept value directly\n",
        "X = np.concatenate((X, np.ones((num_samples, 1))), axis=1) # add a column of 1 to X\n",
        "Y = Y.reshape([-1,1]) # basically encode Y as a  47 x 1 matrix, will still work here but not for exercise 3 so good practice\n",
        "print('X (%d x %d)' %(num_samples, dim + 1))\n",
        "print('Y (%d x 1)' %(num_samples))\n",
        "\n",
        "# GOOD PRACTICE: ALWAYS CHECK MATRIX SHAPES BEFORE MULTIPLYING THEM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "M-rNYY2orXJH",
        "tags": []
      },
      "outputs": [],
      "source": [
        "### main functions of multivariate linear regression\n",
        "def pseudo_inverse(A):\n",
        "    # The pseudo inverse:\n",
        "    # Input: a matrix A\n",
        "    # Output: the pseudo_inverse of A\n",
        "    ### Your code here ###\n",
        "    A_t = np.transpose(A) # transpose A\n",
        "    return np.dot(np.linalg.inv(np.dot(A_t, A)), A_t) # pseudo inverse\n",
        "    \n",
        "def sse(prediction,reference):\n",
        "    # Calculate the sum of square error between the prediction and reference vectors\n",
        "    ### Your code here ###\n",
        "    return np.sum(np.square(prediction - reference)) # sum of square error"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LcDgZgTxrXJI"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(3, 47)\n",
            "[[  139.21067402]\n",
            " [-8738.01911233]\n",
            " [89597.9095428 ]]\n"
          ]
        }
      ],
      "source": [
        "### estimate beta\n",
        "# call the pseudo_inverse to estimate beta from X and Y\n",
        "#print(np.transpose(X).shape) # debug\n",
        "beta = np.dot(pseudo_inverse(X), Y) ### Your code here \n",
        "# print the estimated (learned) parameters\n",
        "print(beta)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gl_6AHA8rXJJ"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sum of square error: 192068324756.665863\n"
          ]
        }
      ],
      "source": [
        "### evaluate the model\n",
        "# calculate the predicted scores\n",
        "prediction = np.dot(X, beta) ### Your code here\n",
        "# calculate the sum of square error\n",
        "error = sse(prediction, Y)\n",
        "print('Sum of square error: %f' %error)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The error is quite bad, but that's because the data itself is pretty bad (check orders of magnitude of input files)\n",
        "One should always check the data before doing ML with it !"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "LiYSlShDrXJJ"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "beta_2:  [3.  2.  0.5]\n",
            "Sum of square error: 0.000000\n"
          ]
        }
      ],
      "source": [
        "### Extra step \n",
        "# generate synthetic scores\n",
        "# NB nomenclature: feature = variable = dimension\n",
        "Ys = 3 * X[:,0] + 2 * X[:,1] + 0.5 * X[:,2] # generate Ys using a linear function of the features of X\n",
        "# perform multivariate linear regression with X and Ys as inputs\n",
        "beta_2 = np.dot(pseudo_inverse(X), Ys) ### Your code here\n",
        "print('beta_2: ', beta_2)\n",
        "# calculate the predicted scores\n",
        "prediction_2 = np.dot(X, beta_2) ### Your code here\n",
        "# calculate the sum of square error\n",
        "error_2 = sse(prediction_2, Ys) \n",
        "print('Sum of square error: %f' %error_2) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "There are 2 definitions of multivariate linear regression: for the first one, what we did is OK\n",
        "For most people, multivariate is actually when we want to predict multiple variables (so multiple columns in Y, and separate beta_i,j coefficients for each variable -> we get a beta matrix instead of a beta vector, as we also had a Y matrix instead of a Y vector)"
      ]
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "colab": {
      "collapsed_sections": [],
      "name": "ex2_multivariate_linear_regression.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
